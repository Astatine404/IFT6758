{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Prog-4",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0g4gXggN12ZX"
      },
      "source": [
        "<center><h1> IFT-6758  </h1></center>\n",
        "<center><h1> Data Science / Science des données  </h1></center> \n",
        "<center><h2> Fall-2021 </h2></center> \n",
        "<center><h3> Prog 4 </h3></center> \n",
        "<center><h3> </h3></center> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12UuwY6TT7Sx"
      },
      "source": [
        "\n",
        "\n",
        "Deadline    : **Dec 22, 11.59 pm EDT** on [Gradescope](https://www.gradescope.com/courses/286503/assignments/1713200)\n",
        "\n",
        "---\n",
        "\n",
        "Date limite :  **Le 22 déc, 23h59 HAE** sur [Gradescope](https://www.gradescope.com/courses/286503/assignments/1713200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0ajvt0GBCOF"
      },
      "source": [
        "**Please use only the following imports.**\n",
        "\n",
        "**DO NOT IMPORT ANYTHING OTHER THAN SUB-PACKAGES OF THESE WHEN NECESSARY.**\n",
        "\n",
        "This is important for running you code!\n",
        "\n",
        "---\n",
        "\n",
        "**Veuillez utiliser uniquement les importations suivantes.**\n",
        "\n",
        "**N'IMPORTEZ RIEN D'AUTRE DES SOUS-PACKAGES DE CEUX-CI LORSQUE NÉCESSAIRE.**\n",
        "\n",
        "Ceci est important pour exécuter votre code!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHlfVVIY12m0"
      },
      "source": [
        "#@title Imports (Run this cell first / Lancez d'abord cette cellule) { run: \"auto\" }\n",
        "\n",
        "# Imports / Importations\n",
        "\n",
        "import nltk\n",
        "\n",
        "import sklearn\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import random\n",
        "import itertools\n",
        "import collections"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mP6EAf2i13E6"
      },
      "source": [
        "[4 points]\n",
        "\n",
        "## Q1. Given a word-document matrix (words along rows and documents along columns), use SVD and obtain the dense word embeddings of the words based on a given `embedding_dimension`. Based on the `word_order` that represents the words indexed by the word-document matrix and the embeddings computed, return the word embeddings ONLY for the requested words `test_words` as a 2D numpy array. \n",
        "\n",
        "**[IMPORTANT: Use SVD only from numpy]**\n",
        "\n",
        "---\n",
        "\n",
        "## Q1. Étant donné une matrice mot-document (mots le long des lignes et documents le long des colonnes), utilisez SVD et obtenez les plongements de mots denses des mots sur la base d'une `embedding_dimension` donnée. Sur la base du `word_order` qui représente les mots indexés par la matrice word-document et les plongements calculés, retournez les plongements de mots UNIQUEMENT pour les mots demandés `test_words` sous forme d'array numpy 2D.\n",
        "\n",
        "**[IMPORTANT: Utilisez le SVD seulement du numpy]**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/ift-6758/files/raw/main/word-doc-matrix.npy\n",
        "!wget https://github.com/ift-6758/files/raw/main/word-order.npy"
      ],
      "metadata": {
        "id": "2ufdEHBfZycD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b07d1cd-f463-479b-9ce2-56c2272135f8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-22 19:33:00--  https://github.com/ift-6758/files/raw/main/word-doc-matrix.npy\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/ift-6758/files/main/word-doc-matrix.npy [following]\n",
            "--2021-12-22 19:33:00--  https://raw.githubusercontent.com/ift-6758/files/main/word-doc-matrix.npy\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 32896 (32K) [application/octet-stream]\n",
            "Saving to: ‘word-doc-matrix.npy’\n",
            "\n",
            "\rword-doc-matrix.npy   0%[                    ]       0  --.-KB/s               \rword-doc-matrix.npy 100%[===================>]  32.12K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2021-12-22 19:33:00 (12.9 MB/s) - ‘word-doc-matrix.npy’ saved [32896/32896]\n",
            "\n",
            "--2021-12-22 19:33:00--  https://github.com/ift-6758/files/raw/main/word-order.npy\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/ift-6758/files/main/word-order.npy [following]\n",
            "--2021-12-22 19:33:00--  https://raw.githubusercontent.com/ift-6758/files/main/word-order.npy\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9600 (9.4K) [application/octet-stream]\n",
            "Saving to: ‘word-order.npy’\n",
            "\n",
            "word-order.npy      100%[===================>]   9.38K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-12-22 19:33:00 (84.0 MB/s) - ‘word-order.npy’ saved [9600/9600]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PodtjZmP2U-k"
      },
      "source": [
        "word_doc_matrix = np.load('word-doc-matrix.npy')\n",
        "word_order = list(np.load('word-order.npy'))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiRJbots11ga",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47b4df30-c0be-4d1e-8a51-411a14c2025b"
      },
      "source": [
        "def q1(data_matrix = word_doc_matrix, word_order = word_order, embedding_dimension=16, test_words = ['wine', 'alarm','smile','jazz']):\n",
        "\n",
        "  assert len(data_matrix) == len(word_order)\n",
        "\n",
        "  \"\"\"\n",
        "  Your solution / Votre solution\n",
        "  \"\"\"\n",
        "\n",
        "  u, s, vh = np.linalg.svd(data_matrix)\n",
        "  embed_matrix = u @ np.diag(s)[:, :embedding_dimension]\n",
        "  word_order = np.array(word_order)\n",
        "  \n",
        "  #Search indices of test_words in word_order\n",
        "  word_ind = np.array([])\n",
        "  for word in test_words:\n",
        "    word_ind = np.concatenate((word_ind, np.where(word_order == word)[0]))\n",
        "\n",
        "  word_ind = word_ind.astype('int32')\n",
        "\n",
        "  test_word_embeddings = embed_matrix[word_ind, :]\n",
        "\n",
        "  assert len(test_word_embeddings) == len(test_words)\n",
        "\n",
        "  return test_word_embeddings \n",
        "\n",
        "q1()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-3.86718753e+01,  1.13109404e+00,  1.15852828e-01,\n",
              "        -4.31726722e-03,  2.50503202e+00,  1.96479131e+00,\n",
              "        -2.97829492e+00,  4.50139536e+00, -1.09742060e+01,\n",
              "         5.18517817e+00, -6.04958900e+00,  6.64823014e-01,\n",
              "        -3.35336667e+00,  4.75507345e+00, -1.85158780e+00,\n",
              "         3.98624922e+00],\n",
              "       [-4.50777268e+01,  8.70227535e+00,  7.16227266e+00,\n",
              "         5.92410327e+00, -5.72510155e+00,  1.11729879e+01,\n",
              "        -3.82783277e-01,  5.83423447e-02, -4.86039840e+00,\n",
              "        -5.70463834e+00, -1.80923999e+00, -4.72055376e+00,\n",
              "         3.57243487e+00, -2.19395489e+00,  7.80409207e-01,\n",
              "         2.52209004e+00],\n",
              "       [-4.02140544e+01, -2.44276414e+00,  8.19119507e+00,\n",
              "        -4.47119457e+00,  2.48522076e+00,  6.12125554e+00,\n",
              "        -4.34202132e+00, -4.82866770e+00,  4.55151522e+00,\n",
              "         3.12617917e+00,  1.61764128e+01,  2.30576693e+00,\n",
              "        -4.46823140e+00,  3.99825386e+00, -6.55612215e+00,\n",
              "        -3.84422243e-01],\n",
              "       [-4.06305336e+01, -3.98531697e-01,  6.07306227e+00,\n",
              "        -1.73042911e+00,  1.40965389e+01,  2.47773735e+00,\n",
              "        -7.00704862e+00,  8.50421152e+00,  3.72758656e+00,\n",
              "        -8.16659532e+00, -7.03694504e+00, -3.02427980e+00,\n",
              "        -1.08438245e+01, -4.18251272e+00, -2.50599652e+00,\n",
              "         2.53430348e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKMkKROaAS9E"
      },
      "source": [
        "[4 points]\n",
        "\n",
        "## Q2. Given a list of sentences and a `test_word`, train a [Word2Vec](https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html) model using the given specifications and return the words `most_similar`, `most_dissimilar` and `neutral` words as described below:\n",
        "\n",
        "**Specifications**\n",
        "\n",
        "* `sentences` - A list of tokenized sentences to use for constructing the Word2Vec vectors\n",
        "* `context_length` - length of the window to generate training data for the Word2Vec model \n",
        "* `embedding_type` - Could be either 'skipgram' or 'cbow'\n",
        "\n",
        "No other preprocessing required. \n",
        "\n",
        "Only fill in the line with `...`\n",
        "\n",
        "Do not change any other parameters! \n",
        "\n",
        "**Return**\n",
        "\n",
        "Use the Word2Vc `model` to determine the following words :\n",
        "\n",
        "* `most_similar` - word most similar to the given `test_word`\n",
        "* `most_dissimilar` - word most dissimilar (or most negatively similar) to the given `test_word`\n",
        "* `neutral` - word that is most similar to the sum of the word vectors corresponding to the determined `most_similar` and `most_dissimilar`\n",
        "\n",
        "Example return: `'happy','sad','meh'`\n",
        "\n",
        "---\n",
        "\n",
        "## Q2.Étant donné une liste de phrases et un `test_word`, entraînez un modèle [Word2Vec](https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html) en utilisant les spécifications données et retournez les mots `most_similar`, `most_dissimilar` et `neutral` comme décrit ci-dessous :\n",
        "\n",
        "**Précisions**\n",
        "\n",
        "* `sentences` - Une liste de phrases tokenisées à utiliser pour construire les vecteurs Word2Vec\n",
        "* `context_length` - longueur de la fenêtre pour générer des données d'entraînement pour le modèle Word2Vec\n",
        "* `embedding_type` - Peut être 'skipgram' ou 'cbow'\n",
        "\n",
        "\n",
        "Aucun autre prétraitement requis.\n",
        "\n",
        "Remplissez uniquement la ligne avec `...`\n",
        "\n",
        "Ne modifiez aucun autre paramètre !\n",
        "\n",
        "\n",
        "**Retour**\n",
        "\n",
        "Utilisez le `modèle` Word2Vc pour déterminer les mots suivants :\n",
        "\n",
        "* `most_similar` - mot le plus similaire au `test_word` donné\n",
        "* `most_dissimilar` - mot le plus différent (ou le plus négativement similaire) au `test_word` donné\n",
        "* `neutral` - mot qui est le plus similaire à la somme des vecteurs de mots correspondant aux `most_similar` et `most_dissimilar` déterminés\n",
        "\n",
        "Exemple de retour : `'heureux','triste','meh'`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "from nltk.corpus import treebank\n",
        "\n",
        "nltk.download('treebank')"
      ],
      "metadata": {
        "id": "ziPVJ1_hzB_-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a6ef82a-b402-4702-ed7b-092780746b5a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfECZLlkAS9E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96f7e290-f07f-4ec0-d257-0e15cb1e4263"
      },
      "source": [
        "def q2(sentences=treebank.sents(), context_length=3, embedding_type='skipgram', test_word='social'):\n",
        "\n",
        "  # Checking for valid values of arguments / Vérification des valeurs valides des arguments\n",
        "  assert embedding_type in ['skipgram','cbow']\n",
        "\n",
        "  \"\"\"\n",
        "  Your solution / Votre solution\n",
        "  \"\"\"\n",
        "\n",
        "  # \n",
        "  sg = int(embedding_type == 'skipgram')\n",
        "  model = Word2Vec(sentences=sentences, window=context_length, sg=sg) # To be completed / À compléter\n",
        "  \n",
        "  most_similar = model.wv.most_similar(positive=[test_word], topn=1)[0][0]\n",
        "\n",
        "  most_dissimilar = model.wv.most_similar(negative=[test_word], topn=1)[0][0]\n",
        "\n",
        "  neutral = model.wv.similar_by_vector(model.wv[most_similar] + model.wv[most_dissimilar], topn=1)[0][0]\n",
        "\n",
        "  return most_similar, most_dissimilar, neutral\n",
        "\n",
        "q2()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('English', 'New', 'Exchange')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qej93G95ARAi"
      },
      "source": [
        "[7 points]\n",
        "\n",
        "##Q3. Given a graph adjacency matrix $A$, perform random walks on the graph from each node $w$ times with length of the walk equal to $l$ and generate an embedding matrix based on the average of visit counts of each node visited during the walks.\n",
        "\n",
        "* The order of nodes indexed by the position is the order of nodes in adjacency matrix $A$\n",
        "* During the random walk, each node $v_i$ has an equal probability of $1/degree(v_i)$ of visiting an adjacent node (random seed is set as 6758).\n",
        "* The embedding of each node $v_i$ is actually the average visit count over the $w$ walks for each of the $l$ nodes visited in the random walk starting from $v_i$\n",
        "* The returned embedding matrix  (numpy array) should contain the node embeddings of all nodes (Each row $i$ is a node embedding of the respective node $i$)\n",
        "* Please do not change the random seed as it controls the order of nodes in the random walks.\n",
        "\n",
        "\n",
        "Given below is an illustration of the computation of the node embedding for node 0, the same applies for all nodes:\n",
        "\n",
        "For $A = \\begin{pmatrix} \n",
        "0 & 1 &1 &1 &1\\\\\n",
        "1 & 0 &1 &1 &1\\\\\n",
        "1 & 1 &0 &1 &1\\\\\n",
        "1 & 1 &1 &0 &1\\\\\n",
        "1 & 1 &1 &1 &0\\\\\n",
        "\\end{pmatrix},  ~l=4 \\text{ and } w=2$\n",
        "\n",
        "For node 0 that is connected to all other nodes 1, 2, 3 and 4 obtaining $w=2$ number of $l=4$ step random walks:\n",
        "* $0 → 1 → 2 → 3$ which gives a visit count vector `[1,1,1,1,0]` since 0,1 and 3 are visited once each.\n",
        "* $0 → 4 → 2 → 4$ which gives a visit count vector `[1,0,1,0,2]` since 0 and 2 are visited once while 4 is visited twice.\n",
        "\n",
        "Averaging the above two visit count vectors gives `[1.0,0.5,1.0,0.5,1.0]` for node 0.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "##Q3. Étant donné une matrice d'adjacence $A$ d'un graphe, effectuez les marches aléatoires sur le graphe de chaque nœud $w $ fois avec une longueur de la marche égale à $l$ et générer une matrice de plongement basée sur la moyenne des nombres de visites de chaque nœud visité pendant les marches.\n",
        "\n",
        "* L'ordre des nœuds indexés par la position est l'ordre des nœuds dans la matrice d'adjacence $A$\n",
        "* Au cours de la marche aléatoire, chaque nœud $v_i$ a une probabilité égale de $1/degree(v_i)$ de visiter un nœud adjacent (la graine aléatoire `seed` est fixée à 6758).\n",
        "* Le plongement de chaque nœud $v_i$ est en fait le nombre moyen de visites sur les $w$ marches pour chacun des $l$ nœuds visités dans la marche aléatoire à partir de $v_i$\n",
        "* La matrice de plongement retourné (array numpy) doit contenir les plongements de nœuds de tous les nœuds (chaque ligne $i$ est un plongement de nœud du nœud respectif $i$)\n",
        "* Veuillez ne pas modifier la graine aléatoire car elle contrôle l'ordre des nœuds dans les marches aléatoires.\n",
        "\n",
        "\n",
        "Ci-dessous, une illustration du calcul du plongement des nœuds pour le nœud 0, il en va de même pour tous les nœuds :\n",
        "\n",
        "Pour $A = \\begin{pmatrix}\n",
        "0 & 1 &1 &1 &1\\\\\n",
        "1 & 0 &1 &1 &1\\\\\n",
        "1 & 1 &0 &1 &1\\\\\n",
        "1 & 1 &1 &0 &1\\\\\n",
        "1 & 1 &1 &1 &0\\\\\n",
        "\\end{pmatrix}, ~l=4 \\text{ et } w=2$\n",
        "\n",
        "Pour le nœud 0 qui est connecté à tous les autres nœuds 1, 2, 3 et 4 obtenant $w=2$ nombre de marches aléatoires $l=4$ pas :\n",
        "* $0 → 1 → 2 → 3$ qui donne un vecteur de nombre de visites `[1,1,1,1,0]` puisque 0,1, 2 et 3 sont visités une fois chacun.\n",
        "* $0 → 4 → 2 → 4$ qui donne un vecteur de nombre de visites `[1,0,1,0,2]` puisque 0 et 2 sont visités une fois tandis que 4 est visité deux fois.\n",
        "\n",
        "La moyenne des deux vecteurs de nombre de visites ci-dessus donne `[1.0,0.5,1.0,0.5,1.0]` pour le nœud 0."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/ift-6758/files/raw/main/graph-adjacency-matrix.npy"
      ],
      "metadata": {
        "id": "Km0GvNhOaAv-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0bc0853-9b34-4e2b-dd14-80eb6d98560f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-22 19:42:03--  https://github.com/ift-6758/files/raw/main/graph-adjacency-matrix.npy\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/ift-6758/files/main/graph-adjacency-matrix.npy [following]\n",
            "--2021-12-22 19:42:03--  https://raw.githubusercontent.com/ift-6758/files/main/graph-adjacency-matrix.npy\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3328 (3.2K) [application/octet-stream]\n",
            "Saving to: ‘graph-adjacency-matrix.npy’\n",
            "\n",
            "graph-adjacency-mat 100%[===================>]   3.25K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-12-22 19:42:03 (24.3 MB/s) - ‘graph-adjacency-matrix.npy’ saved [3328/3328]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(6758)\n",
        "np.random.seed(6758)\n",
        "adjacency_matrix = np.load('graph-adjacency-matrix.npy')"
      ],
      "metadata": {
        "id": "A_Z9Yyp7-BBS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxsFkiJ-ssnf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7746b6c5-2e26-4003-a4b4-a2330ffad352"
      },
      "source": [
        "def q3(A = adjacency_matrix, l=5, w=5):\n",
        "  \"\"\"\n",
        "  Your solution / Votre solution\n",
        "  \"\"\"\n",
        "  n_nodes = A.shape[0]\n",
        "  \n",
        "  node_embeddings = []\n",
        "  for start_node in range(n_nodes):\n",
        "    walks = []\n",
        "    for walk_no in range(w):\n",
        "      curr_node = start_node\n",
        "      visits = np.zeros((n_nodes,))\n",
        "      visits[curr_node] += 1\n",
        "      for step in range(l-1):\n",
        "        adj_nodes = []\n",
        "        # Check adjacents of curr_node\n",
        "        for adj_node in range(n_nodes):\n",
        "          if A[curr_node][adj_node] > 0:\n",
        "            adj_nodes.append(adj_node)\n",
        "        # Choose random adj node\n",
        "        curr_node = adj_nodes[random.randrange(0, len(adj_nodes))]\n",
        "        visits[curr_node] += 1\n",
        "      walks.append(visits)\n",
        "    node_embeddings.append(np.array(walks).mean(axis=0))\n",
        "\n",
        "\n",
        "  #node_embeddings = np.array([[]])\n",
        "  node_embeddings = np.array(node_embeddings)\n",
        "\n",
        "  assert len(node_embeddings) == len(adjacency_matrix)\n",
        "\n",
        "  return node_embeddings\n",
        "\n",
        "q3()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1. , 0.2, 0.2, 0. , 0.2, 0.2, 0.2, 0.2, 0.4, 0. , 0. , 0.2, 0.2,\n",
              "        0. , 0.4, 0.2, 0.2, 0.2, 0.6, 0.4],\n",
              "       [0. , 1.2, 0. , 0.4, 0. , 0.6, 0.4, 0. , 0.6, 0.4, 0.4, 0. , 0. ,\n",
              "        0. , 0.2, 0. , 0.2, 0. , 0. , 0.6],\n",
              "       [0.2, 0.2, 1. , 0.6, 0.4, 0.2, 0. , 0. , 0. , 0.6, 0. , 0.4, 0. ,\n",
              "        0.4, 0.2, 0.2, 0. , 0.2, 0.4, 0. ],\n",
              "       [0.2, 0.4, 0.2, 1.2, 0.2, 0. , 0.2, 0. , 0.2, 0. , 0. , 0. , 0.2,\n",
              "        0.4, 0.2, 0.4, 0.2, 0.2, 0.2, 0.6],\n",
              "       [0.2, 0.4, 0.4, 0. , 1. , 0.4, 0. , 0. , 0.6, 0. , 0.2, 0.2, 0. ,\n",
              "        0.4, 0.2, 0.2, 0.2, 0.4, 0.2, 0. ],\n",
              "       [0.2, 0. , 0.4, 0. , 0.2, 1. , 0.4, 0. , 0. , 0. , 0.2, 0.4, 0.2,\n",
              "        0.6, 0.4, 0.4, 0. , 0.2, 0.2, 0.2],\n",
              "       [0. , 0.2, 0. , 0. , 0.2, 0.4, 1.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0. ,\n",
              "        0.2, 0.2, 0.2, 0.4, 0.2, 0.2, 0.6],\n",
              "       [0.2, 0. , 0.2, 0.4, 0.6, 0. , 0. , 1.4, 0. , 0. , 0.2, 0. , 0.2,\n",
              "        0.4, 0.2, 0.2, 0. , 0.2, 0.6, 0.2],\n",
              "       [0.4, 0.2, 0.4, 0. , 0. , 0. , 0. , 0.4, 1.4, 0.2, 0.2, 0. , 0. ,\n",
              "        0.6, 0. , 0.8, 0. , 0. , 0. , 0.4],\n",
              "       [0. , 0.2, 0.2, 0.4, 0. , 0. , 0. , 0.4, 0. , 1. , 0.2, 0.2, 0.4,\n",
              "        0.6, 0.2, 0. , 0.4, 0.8, 0. , 0. ],\n",
              "       [0.2, 0.2, 0.4, 0.2, 0. , 0.2, 0.2, 0.2, 0.2, 0.2, 1.4, 0. , 0. ,\n",
              "        0.4, 0. , 0. , 0.2, 0.2, 0.4, 0.4],\n",
              "       [0. , 0.4, 0. , 0.2, 0.2, 0. , 0.6, 0.4, 0. , 0. , 0.2, 1.6, 0. ,\n",
              "        0.4, 0. , 0. , 0.2, 0.2, 0.6, 0. ],\n",
              "       [0. , 0. , 0.6, 0. , 0. , 0. , 0. , 0.4, 0.8, 0.2, 0. , 0. , 1.2,\n",
              "        0.4, 0.2, 0.2, 0. , 0.6, 0. , 0.4],\n",
              "       [0. , 0.2, 0.2, 0.4, 0. , 0. , 0. , 0.2, 0.2, 0.2, 0. , 0.4, 0.2,\n",
              "        1.2, 0.2, 0.6, 0.4, 0.2, 0.2, 0.2],\n",
              "       [0.2, 0.4, 0.2, 0.2, 0.4, 0.2, 0. , 0. , 0. , 0. , 0.4, 0.2, 0. ,\n",
              "        0.4, 1.2, 0. , 0. , 0.6, 0.6, 0. ],\n",
              "       [0.2, 0.2, 0.4, 0.2, 0.2, 0.4, 0. , 0. , 0.2, 0.6, 0. , 0. , 0.8,\n",
              "        0. , 0.2, 1.2, 0. , 0. , 0.4, 0. ],\n",
              "       [0.2, 0.2, 0. , 0.6, 0.2, 0.2, 0.4, 0. , 0.2, 0. , 0.2, 0.2, 0. ,\n",
              "        0.2, 0.2, 0. , 1.2, 0.6, 0. , 0.4],\n",
              "       [0.6, 0. , 0.4, 0.2, 0. , 0.6, 0. , 0.6, 0.2, 0.4, 0. , 0. , 0.2,\n",
              "        0.2, 0.2, 0.2, 0.2, 1. , 0. , 0. ],\n",
              "       [0.2, 0. , 0.2, 0.2, 0.4, 0.4, 0.2, 0.4, 0. , 0. , 0.6, 0.4, 0.2,\n",
              "        0.2, 0.2, 0. , 0.2, 0. , 1. , 0.2],\n",
              "       [0.2, 0.2, 0.6, 0. , 0. , 0. , 0. , 0. , 0.6, 0.4, 0.2, 0.2, 0.4,\n",
              "        0.2, 0.2, 0.2, 0. , 0. , 0.6, 1. ]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTI-7W7mz1Xz"
      },
      "source": [
        "[5 points]\n",
        "\n",
        "#Q4. Given a node embedding matrix that contains a node embedding vector for each node, finds the most similar node for each node in the graph. Assume that the node indexes start from $0,..., n-1$ where $n$ is the number of nodes.                                                                                    \n",
        "\n",
        "For example : For a given $5 \\times 20$ embedding matrix corresponding to 20-dimensional embeddings of the 5 nodes `[0,1,2,3,4]`, `most_similar_node_list` could be `[4,3,4,1,2]` indicating that 4 is the most similar node 0, 3 is the most similar node to 1, 4 is the most similar node to 2 and so on.\n",
        "\n",
        "---\n",
        "\n",
        "#Q4. Étant donné une matrice de plongement de nœuds contenant un vecteur de plongement de nœuds pour chaque nœud, recherche le nœud le plus similaire pour chaque nœud du graphe. Supposons que les index de nœuds commencent à $0,..., n-1$ où $n$ est le nombre de nœuds.\n",
        "\n",
        "Par exemple : Pour une matrice de plongement donnée de $5 \\times 20$ correspondant aux plongements en 20 dimensions de 5 nœuds `[0,1,2,3,4]`, `most_similar_node_list` pourrait être `[4,3,4,1,2]` indiquant que 4 est le nœud le plus similaire à 0, 3 est le nœud le plus similaire à 1, 4 est le nœud le plus similaire à 2 et ainsi de suite.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/ift-6758/files/raw/main/node-embeddings.npy"
      ],
      "metadata": {
        "id": "NHCQ61oNaGLN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "405d93e9-04a1-4189-9df0-98c570e981ac"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-22 19:42:27--  https://github.com/ift-6758/files/raw/main/node-embeddings.npy\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/ift-6758/files/main/node-embeddings.npy [following]\n",
            "--2021-12-22 19:42:27--  https://raw.githubusercontent.com/ift-6758/files/main/node-embeddings.npy\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3328 (3.2K) [application/octet-stream]\n",
            "Saving to: ‘node-embeddings.npy.1’\n",
            "\n",
            "node-embeddings.npy 100%[===================>]   3.25K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-12-22 19:42:27 (45.1 MB/s) - ‘node-embeddings.npy.1’ saved [3328/3328]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "node_embeddings = np.load('node-embeddings.npy')"
      ],
      "metadata": {
        "id": "tcQ2aw6J_oGq"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tiHceZX7ovx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c04bbd17-9276-46e6-92bb-632b03435abe"
      },
      "source": [
        "def q4(embedding_matrix = node_embeddings):\n",
        "\n",
        "    \"\"\"\n",
        "    Your solution / Votre solution\n",
        "    \"\"\"\n",
        "\n",
        "    most_similar_node_list = list()\n",
        "\n",
        "    for node in range(embedding_matrix.shape[0]):\n",
        "      max_similarity = -np.inf\n",
        "      most_similar = None\n",
        "      for node_ in range(embedding_matrix.shape[0]):\n",
        "        if node == node_:\n",
        "          continue\n",
        "        similarity = np.dot(embedding_matrix[node, :], embedding_matrix[node_, :]) / (np.linalg.norm(embedding_matrix[node, :]) * np.linalg.norm(embedding_matrix[node_, :]))\n",
        "        if similarity > max_similarity:\n",
        "          most_similar = node_\n",
        "          max_similarity = similarity\n",
        "      most_similar_node_list.append(most_similar)\n",
        "\n",
        "\n",
        "    # Convert to list if you have it as a np array / Convertissez à une liste si vous l'avez comme un array np\n",
        "    if type(most_similar_node_list) != list:\n",
        "      most_similar_node_list = list(most_similar_node_list)\n",
        "\n",
        "    # Ensuring that every node has the most similar node specified / S'assurer que chaque nœud a le nœud le plus similaire spécifié\n",
        "    assert len(most_similar_node_list) == len(embedding_matrix)\n",
        "\n",
        "    return most_similar_node_list\n",
        "\n",
        "q4()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[14, 12, 15, 5, 12, 19, 7, 6, 16, 14, 0, 5, 1, 18, 0, 2, 18, 0, 16, 5]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnTB3dw5d_Ny"
      },
      "source": [
        "Packaging all the above functions into a class for the solution file to submit on Gradescope.\n",
        "\n",
        "---\n",
        "\n",
        "Empaqueter toutes les fonctions ci-dessus dans une classe pour le fichier de solution à remettre sur Gradescope."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDKb9A0_i__P"
      },
      "source": [
        "class Prog4:\n",
        "  \n",
        "  def q1(self, data_matrix = word_doc_matrix, word_order = word_order, embedding_dimension=16, test_words = ['wine', 'alarm','smile','jazz']):\n",
        "    return q1(data_matrix, word_order, embedding_dimension, test_words)\n",
        "  \n",
        "  def q2(self, sentences=treebank.sents(), context_length=3, embedding_type='skipgram', test_word='social'):\n",
        "    return q2(sentences, context_length, embedding_type, test_word)\n",
        "\n",
        "  def q3(self, A = adjacency_matrix, l=5, w=5):\n",
        "    random.seed(6758)\n",
        "    np.random.seed(6758)\n",
        "    return q3(A, l, w)\n",
        "\n",
        "  def q4(self, embedding_matrix = node_embeddings):\n",
        "    return q4(embedding_matrix)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prog = Prog4()\n",
        "print(prog.q1())\n",
        "print(prog.q2())\n",
        "print(prog.q3())\n",
        "print(prog.q4())"
      ],
      "metadata": {
        "id": "b0TnHw7OliNc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "787c3f6d-df6a-42fa-8349-6beb93e2ad73"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-3.86718753e+01  1.13109404e+00  1.15852828e-01 -4.31726722e-03\n",
            "   2.50503202e+00  1.96479131e+00 -2.97829492e+00  4.50139536e+00\n",
            "  -1.09742060e+01  5.18517817e+00 -6.04958900e+00  6.64823014e-01\n",
            "  -3.35336667e+00  4.75507345e+00 -1.85158780e+00  3.98624922e+00]\n",
            " [-4.50777268e+01  8.70227535e+00  7.16227266e+00  5.92410327e+00\n",
            "  -5.72510155e+00  1.11729879e+01 -3.82783277e-01  5.83423447e-02\n",
            "  -4.86039840e+00 -5.70463834e+00 -1.80923999e+00 -4.72055376e+00\n",
            "   3.57243487e+00 -2.19395489e+00  7.80409207e-01  2.52209004e+00]\n",
            " [-4.02140544e+01 -2.44276414e+00  8.19119507e+00 -4.47119457e+00\n",
            "   2.48522076e+00  6.12125554e+00 -4.34202132e+00 -4.82866770e+00\n",
            "   4.55151522e+00  3.12617917e+00  1.61764128e+01  2.30576693e+00\n",
            "  -4.46823140e+00  3.99825386e+00 -6.55612215e+00 -3.84422243e-01]\n",
            " [-4.06305336e+01 -3.98531697e-01  6.07306227e+00 -1.73042911e+00\n",
            "   1.40965389e+01  2.47773735e+00 -7.00704862e+00  8.50421152e+00\n",
            "   3.72758656e+00 -8.16659532e+00 -7.03694504e+00 -3.02427980e+00\n",
            "  -1.08438245e+01 -4.18251272e+00 -2.50599652e+00  2.53430348e+00]]\n",
            "('English', 'New', 'Exchange')\n",
            "[[1.  0.2 0.2 0.  0.2 0.2 0.2 0.2 0.4 0.  0.  0.2 0.2 0.  0.4 0.2 0.2 0.2\n",
            "  0.6 0.4]\n",
            " [0.  1.2 0.  0.4 0.  0.6 0.4 0.  0.6 0.4 0.4 0.  0.  0.  0.2 0.  0.2 0.\n",
            "  0.  0.6]\n",
            " [0.2 0.2 1.  0.6 0.4 0.2 0.  0.  0.  0.6 0.  0.4 0.  0.4 0.2 0.2 0.  0.2\n",
            "  0.4 0. ]\n",
            " [0.2 0.4 0.2 1.2 0.2 0.  0.2 0.  0.2 0.  0.  0.  0.2 0.4 0.2 0.4 0.2 0.2\n",
            "  0.2 0.6]\n",
            " [0.2 0.4 0.4 0.  1.  0.4 0.  0.  0.6 0.  0.2 0.2 0.  0.4 0.2 0.2 0.2 0.4\n",
            "  0.2 0. ]\n",
            " [0.2 0.  0.4 0.  0.2 1.  0.4 0.  0.  0.  0.2 0.4 0.2 0.6 0.4 0.4 0.  0.2\n",
            "  0.2 0.2]\n",
            " [0.  0.2 0.  0.  0.2 0.4 1.2 0.2 0.2 0.2 0.2 0.2 0.  0.2 0.2 0.2 0.4 0.2\n",
            "  0.2 0.6]\n",
            " [0.2 0.  0.2 0.4 0.6 0.  0.  1.4 0.  0.  0.2 0.  0.2 0.4 0.2 0.2 0.  0.2\n",
            "  0.6 0.2]\n",
            " [0.4 0.2 0.4 0.  0.  0.  0.  0.4 1.4 0.2 0.2 0.  0.  0.6 0.  0.8 0.  0.\n",
            "  0.  0.4]\n",
            " [0.  0.2 0.2 0.4 0.  0.  0.  0.4 0.  1.  0.2 0.2 0.4 0.6 0.2 0.  0.4 0.8\n",
            "  0.  0. ]\n",
            " [0.2 0.2 0.4 0.2 0.  0.2 0.2 0.2 0.2 0.2 1.4 0.  0.  0.4 0.  0.  0.2 0.2\n",
            "  0.4 0.4]\n",
            " [0.  0.4 0.  0.2 0.2 0.  0.6 0.4 0.  0.  0.2 1.6 0.  0.4 0.  0.  0.2 0.2\n",
            "  0.6 0. ]\n",
            " [0.  0.  0.6 0.  0.  0.  0.  0.4 0.8 0.2 0.  0.  1.2 0.4 0.2 0.2 0.  0.6\n",
            "  0.  0.4]\n",
            " [0.  0.2 0.2 0.4 0.  0.  0.  0.2 0.2 0.2 0.  0.4 0.2 1.2 0.2 0.6 0.4 0.2\n",
            "  0.2 0.2]\n",
            " [0.2 0.4 0.2 0.2 0.4 0.2 0.  0.  0.  0.  0.4 0.2 0.  0.4 1.2 0.  0.  0.6\n",
            "  0.6 0. ]\n",
            " [0.2 0.2 0.4 0.2 0.2 0.4 0.  0.  0.2 0.6 0.  0.  0.8 0.  0.2 1.2 0.  0.\n",
            "  0.4 0. ]\n",
            " [0.2 0.2 0.  0.6 0.2 0.2 0.4 0.  0.2 0.  0.2 0.2 0.  0.2 0.2 0.  1.2 0.6\n",
            "  0.  0.4]\n",
            " [0.6 0.  0.4 0.2 0.  0.6 0.  0.6 0.2 0.4 0.  0.  0.2 0.2 0.2 0.2 0.2 1.\n",
            "  0.  0. ]\n",
            " [0.2 0.  0.2 0.2 0.4 0.4 0.2 0.4 0.  0.  0.6 0.4 0.2 0.2 0.2 0.  0.2 0.\n",
            "  1.  0.2]\n",
            " [0.2 0.2 0.6 0.  0.  0.  0.  0.  0.6 0.4 0.2 0.2 0.4 0.2 0.2 0.2 0.  0.\n",
            "  0.6 1. ]]\n",
            "[14, 12, 15, 5, 12, 19, 7, 6, 16, 14, 0, 5, 1, 18, 0, 2, 18, 0, 16, 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DeS0pUXTq0j1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}